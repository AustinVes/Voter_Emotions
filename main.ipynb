{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlHVPA/f1nFioLZWkPexAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AustinVes/Voter_Emotions/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnBMFcvdJpd9",
        "colab_type": "text"
      },
      "source": [
        "# Sourcing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqj-MF2eNybE",
        "colab_type": "text"
      },
      "source": [
        "The data I analyse comes from the American National Election Studies (ANES). Specifically, I use data from their 2016 ANES Time Series Study on “electoral participation, voting behavior, public opinion, media exposure, cognitive style, and values and predispositions” of Americans during the 2016 elections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Owg_eAEN2Gb",
        "colab_type": "text"
      },
      "source": [
        "*“ANES is a collaboration of Stanford University and the University of Michigan, with funding by the National Science Foundation… The mission of the American National Election Studies (ANES) is to inform explanations of election outcomes by providing… high quality data from its own surveys on voting, public opinion, and political participation.”* -[ANES](https://electionstudies.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVNpymoyN5Ih",
        "colab_type": "text"
      },
      "source": [
        "The 2016 ANES Time Series Study dataset mainly constitutes survey responses taken both before and after the elections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtu3lOB1N88u",
        "colab_type": "text"
      },
      "source": [
        "*“Data collection for the ANES 2016 Time Series Study began in early September and continued into January, 2017. Pre-election interviews were conducted with study respondents during the two months prior to the 2016 elections and were followed by post-election reinterviewing beginning November 9, 2016… Face-to-face interviewing was complemented with data collection on the Internet.  Data collection was conducted in the two modes independently, using separate samples but substantially identical questionnaires. Web-administered cases constituted a representative sample separate from the face-to-face.”*  -[ANES](https://electionstudies.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPsRbc9qN_yf",
        "colab_type": "text"
      },
      "source": [
        "This dataset is currently available for free [here](https://electionstudies.org/data-center/2016-time-series-study/) from the ANES website, but you will need to have an account with ANES to download it. This repository also contains several copies of this dataset, downloaded 04/06/2020. The dataset comes with a [User Guide and Codebook](https://electionstudies.org/wp-content/uploads/2018/12/anes_timeseries_2016_userguidecodebook.pdf) and [Methodology Report](https://electionstudies.org/wp-content/uploads/2018/12/anes_timeseries_2016_userguidecodebook.pdf), along with many other supporting documents available [here](https://electionstudies.org/data-center/2016-time-series-study/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94M57Dc0OBe4",
        "colab_type": "text"
      },
      "source": [
        "Here are the Terms of Use from ANES, which I accept:\n",
        "* Use these datasets solely for research or statistical purposes and not for investigation of specific survey respondents.\n",
        "* Make no use of the identity of any survey respondent(s) discovered intentionally or inadvertently, and to advise ANES of any such discovery (anes@electionstudies.org)\n",
        "* Cite ANES data and documentation in your work that makes use of the data and documentation. Authors of publications based on ANES data should send citations of their published works to ANES for inclusion in our bibliography of related publications.\n",
        "* You acknowledge that the original collector of the data, ANES, and the relevant funding agency/agencies bear no responsibility for use of the data or for interpretations or inferences based upon such uses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e49XQKtO2gU",
        "colab_type": "text"
      },
      "source": [
        "## Downloading\n",
        "\n",
        "Because downloading the 2016 ANES Time Series Study dataset from the ANES website requires creating an account, for the purposes of loading it into this Google Colab notebook, I made a copy of the dataset available publically in this GitHub repository.\n",
        "\n",
        "ANES offers this dataset in several different file formats. After experimenting with all the formats and confirming they contain the same amount of data, I chose to work with the \"raw\" ASCII file because I best understood how to manipulate it. That said, all the analysis I present here (after sanitation) is the same no matter which format you draw from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nis6Mr-F7z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('anes_timeseries_2016_rawdata.txt'):\n",
        "    !wget https://raw.githubusercontent.com/AustinVes/Voter_Emotions/master/data/ASCII/anes_timeseries_2016_rawdata.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqvM2BDobSmy",
        "colab_type": "text"
      },
      "source": [
        "The raw data file contains plaintext delimiter-separated values (delimiter = \"|\") in fixed-width columns. I load it into a Pandas dataframe with the low_memory flag disabled to avoid winding up with mixed-type columns from parsing the file in chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESsJpPRuajBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('anes_timeseries_2016_rawdata.txt', delimiter='|', low_memory=False)\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD6Wt9Qtg_rD",
        "colab_type": "text"
      },
      "source": [
        "## Understanding the Data Structure\n",
        "\n",
        "Everything in this section is explained in greater detail in the [User Guide and Codebook](https://electionstudies.org/wp-content/uploads/2018/12/anes_timeseries_2016_userguidecodebook.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPXrPcUFCDKJ",
        "colab_type": "text"
      },
      "source": [
        "This dataset consists entirely of survey data. Each column corresponds to a variable describing some aspect of the interviews (responses to a survey question, info about testing conditions, sampling weights, etc.). Each row corresponds to an individual respondent and is persistent through the whole study, meaning that even if a respondent was interviewed multiple times, their data is all contained in their one row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfmJCaaxCFYn",
        "colab_type": "text"
      },
      "source": [
        "This dataset includes results from two distinct interview methodologies: face-to-face (FtF) and online survey. In both cases, interviews were carried out on a sampling of people pre-election and then a subset of those people were also interviewed post-election. Nobody was interviewed post-election that wasn't interviewed pre-election. Respondants from each respective methodology make up their own stratified samples but the dataset provides weights for combining the two groups if you want to analyze them together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfdxWjfVCIBG",
        "colab_type": "text"
      },
      "source": [
        "This study was carried out using stratified sampling. Along with each row, the dataset provides a number of different weights for bootstrapping representative samples of U.S. voters, depending on which of the following subsets of respondents you want to analyze:<br/>\n",
        "* full sample using post‐election survey only or both pre and post<br/>\n",
        "* full sample using pre‐election survey data only<br/>\n",
        "* face‐to‐face mode alone, using the post‐election survey or both pre and * post<br/>\n",
        "* face‐to‐face mode alone, using pre‐election survey data only<br/>\n",
        "* Internet mode alone, using data from both pre‐ and post‐election or post alone<br/>\n",
        "* Internet mode alone, using data from only the pre‐election survey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO2bkjcaCKSQ",
        "colab_type": "text"
      },
      "source": [
        "The variables all follow the same naming convention, that is:<br/>\n",
        "\"V\" + study year (YY) + 1-digit section ID + 3-digit unique code (+ optional letter)<br/>\n",
        "Examples: V166002, V162371b, V164012<br/>\n",
        "The section ID code refers to which part of the study that variable is from (e.g. pre‐election interview, post‐election administrative variables, etc.). Beyond that, this naming scheme makes it impossible to intuit and difficult to remember what each variable means. If you want to work with this dataset, be ready to constantly cross-reference the codebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIUiVVOFCMXH",
        "colab_type": "text"
      },
      "source": [
        "The values of categorical variables are encoded numerically as described in the codebook. Missing data is also encoded numerically as such:<br/>\n",
        "‐1 = Inapplicable<br/>\n",
        "‐2 = Text responses available in separate file or coded version will be included in future release<br/>\n",
        "‐3 = Restricted<br/>\n",
        "‐4 = Error<br/>\n",
        "‐5 = Breakoff, sufficient partial IW<br/>\n",
        "‐6 = No post‐election interview<br/>\n",
        "‐7 = No post data, deleted due to incomplete IW<br/>\n",
        "‐8 = Don’t know<br/>\n",
        "‐9 = Refused<br/>\n",
        "...At least in theory. I found a few odd exceptions to these rules in the dataset, which leads nicely into the next step of the process:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7adrr-7eZ2e",
        "colab_type": "text"
      },
      "source": [
        "## Sanitizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqJhoMyKV-tb",
        "colab_type": "text"
      },
      "source": [
        "In exploring the dataset, the only obvious errors I found were related to these missing data codes. For instance, though almost all columns use these codes where there would otherwise be nothing, there is exactly one column in the whole dataset that uses empty cells instead: V162084. It being the only example and there being no justification given, I assume this was a mistake. I replace all the \"empty\" cells (they actually contain three spaces) with -4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpESmELedYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "V162084_empty = df['V162084'].str.isspace()\n",
        "df.loc[V162084_empty, 'V162084'] = -4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K5Z4ALJfPgD",
        "colab_type": "text"
      },
      "source": [
        "Next, almost all columns just code missing data as numbers (e.g. -1), but some columns also include the description of each missing data code (e.g. \"-1. Inapplicable\") which means those columns get interpreted incorrectly as objects (strings). I identify these cells using a regex that matches the sequence of a minus sign, a single digit, a period, then a space, and I replace them with their intended numerical value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAGUiOeAxU1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_missing_data_desc(cell):\n",
        "  if type(cell) == str and re.search('-\\d. ', cell):\n",
        "    return pd.to_numeric(cell[:cell.find('.')])\n",
        "  else:\n",
        "    return cell\n",
        "\n",
        "object_cols = df.select_dtypes(include='object')\n",
        "df.update(object_cols.applymap(remove_missing_data_desc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfCbkw3PCTfU",
        "colab_type": "text"
      },
      "source": [
        "Now that I've removed all erroneous text from the missing data codes, I ask Pandas to re-interpret each object column's datatype to make every column numerical that should be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmHQNV4EC9Qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.apply(pd.to_numeric, errors='ignore')\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FOQVe9SS5Nh",
        "colab_type": "text"
      },
      "source": [
        "In addition to the error codes provided at the beginning of the codebook, I also found these error codes used in many columns:<br/>\n",
        "-99 = Refused<br/>\n",
        "-89 = Don't recognize (don't know who this is)<br/>\n",
        "-88 = Don’t know (where to rate)<br/>\n",
        "96 = Don’t know<br/>\n",
        "97 = Refused<br/>\n",
        "99 = Not answered; The answer recorded by the interviewer is uninterpretable<br/>\n",
        "99 = Unknown<br/>\n",
        "99 = Haven’t thought much about this<br/>\n",
        "998 = Don’t know (where to rate)<br/>\n",
        "999 = Don’t recognize (don’t know who this is)<br/>\n",
        "9998 = Don't know<br/>\n",
        "9999 = Refused\n",
        "\n",
        "Again, I don't know why these were included except that they were mistakes. Some of these are present in around 100 columns, in many cases alongside the correct codes. All of them ignore the otherwise established conventions for numbering. Several of them are redundant both with each other and with the existing codes. There is a 96, 97, and 99, but no 98 (I checked). Worst of all, not only is 99 used to mean three different things, but it's also a genuine datapoint in several columns.\n",
        "\n",
        "To begin correcting these errant codes, I map each of them to the documented missing data code they most closely represent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxrY8HDmxY4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_codes = pd.Series({\n",
        "    -99: -9,\n",
        "    -89: -8,\n",
        "    -88: -8,\n",
        "    96: -8,\n",
        "    97: -9,\n",
        "    99: -9,\n",
        "    998: -8,\n",
        "    999: -8,\n",
        "    9998: -8,\n",
        "    9999: -9\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rai4Hl5y2f2G",
        "colab_type": "text"
      },
      "source": [
        "Next, I replace all cases I know for sure are one of these errant codes with their appropriate counterpart. I am sure -99, -89, and -88 are always missing data codes because all numerical data in this dataset is positive. I am also sure 998, 999, 9998, and 9999 are always missing data codes because all numerical data in this dataset is within the range 0-100 (with the exception of one column, V161264x, which encodes its categorical data with 3-digit numerical-codes but does not contain 998 or 999)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRJGAmQm6SWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace(correct_codes.drop(labels=[96,97,99]), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU_hZ9YGW83Z",
        "colab_type": "text"
      },
      "source": [
        "Finally, I replace all cases where 96, 97, or 99 are being used as missing data codes and not as genuine datapoints. I determine which is which through a litmus test I discovered by exploring the dataset: 96, 97, and 99 are not used as missing data codes in any column with actual values greater than 15. Likewise, 96, 97, and 99 are not used as actual data in any column where the next greatest value is less than 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqhT0RkrWB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "def fix_unclear_codes(col):\n",
        "  unclear_codes = [96,97,99]\n",
        "  col = col.copy()\n",
        "  orig_col = col.copy()\n",
        "\n",
        "  # remove all non-numeric values from series\n",
        "  col = col[col.apply(lambda x: is_numeric_dtype(type(x)))]\n",
        "  # remove all instances of potential missing data codes from series\n",
        "  col = col[col.apply(lambda x: x not in unclear_codes)]\n",
        "  \n",
        "  if col.max() < 101:\n",
        "    orig_col = orig_col.apply(lambda x: correct_codes[x] if x in unclear_codes else x)\n",
        "  \n",
        "  return orig_col\n",
        "\n",
        "df = df.apply(fix_unclear_codes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okwbslK7fmXU",
        "colab_type": "text"
      },
      "source": [
        "At this point, the entire dataset is sanitized so that there are no empty cells, all numerical columns are actually formatted as such, and only the most appropriate missing data codes as documented in the beginning of the codebook are used. If you want to work with the dataframe in this condition, you should stop here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCry0AwWjJg4",
        "colab_type": "text"
      },
      "source": [
        "In this analysis, though, I care less about preserving the causes of the missing data than I do about making my mathematical analysis simpler and without interference from all these missing data codes. For that reason, I go back on a portion of the work I just accomplished by replacing all the missing data codes in the dataset with NaNs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEPEQFklShA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.applymap(lambda x: np.nan if (is_numeric_dtype(type(x)) and x < 0) else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEzaU1E9CuxV",
        "colab_type": "text"
      },
      "source": [
        "## Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_gRqg99Cw6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}